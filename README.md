# ğŸ§  Multi-Modal Sentiment Analysis (Text + Image)

An end-to-end **Multi-Modal Sentiment Analysis system** that predicts sentiment by jointly analyzing **text and image data** from social media posts.

The project uses **Transformer-based text encoding (BERT)** and **CNN-based image feature extraction (ResNet-50)**, followed by a fusion-based classifier and a **Streamlit web interface** for interactive inference.

---

## ğŸš€ Key Features

- ğŸ“ **Text Feature Extraction** using **BERT (Hugging Face Transformers)**
- ğŸ–¼ï¸ **Image Feature Extraction** using **ResNet-50 (ImageNet pretrained)**
- ğŸ”— **Late fusion** of text and image embeddings
- âš–ï¸ **Class-weighted Loss** to handle class imbalance
- ğŸ”§ **Selective fine-tuning** of the last BERT layer
- ğŸ“Š Strong evaluation performance (**Macro-F1 = 0.74**)
- ğŸŒ **Streamlit web app** for real-time predictions
- â˜ï¸ Runs offline (full inference) and online (demo mode)

---

## ğŸ“‚ Project Structure

multimodal-sentiment/
â”‚
â”œâ”€â”€ 01_dataset_loader.ipynb
â”œâ”€â”€ 02_text_preprocess.ipynb
â”œâ”€â”€ 03_image_preprocess.ipynb
â”œâ”€â”€ 04_multimodal_model.ipynb
â”œâ”€â”€ 05_train.ipynb
â”œâ”€â”€ 06_evaluate.ipynb
â”œâ”€â”€ 07_streamlit_app.ipynb
â”‚
â”œâ”€â”€ streamlit_app.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ report.pdf
â”‚
â”œâ”€â”€ MVSA_Single/
â”‚ â”œâ”€â”€ data/ (downloaded from Kaggle)
â”‚ â”œâ”€â”€ labelResultsAll.txt (Kaggle labels)



---

## ğŸ“Š Dataset Source

This project uses the **MVSA-Single** (multi-view sentiment analysis) dataset from Kaggle:

ğŸ‘‰ **Download here:**  
https://www.kaggle.com/datasets/vincemarcs/mvsasingle?utm_source=chatgpt.com

### How to use it

After downloading:
1. Extract the dataset
2. Place the folder as:

multimodal-sentiment/MVSA_Single/
â”œâ”€â”€ data/
â”œâ”€â”€ labelResultsAll.txt

The code expects:
- Text files: `*.txt` for each post
- Images: `*.jpg` in `data/`
- Labels: `labelResultsAll.txt` containing textâ€“image sentiment annotations

---

## ğŸ—ï¸ Model Architecture Summary

### Text Encoder
- Model: `BERT-base-uncased`
- Embedding size: 768

### Image Encoder
- Model: `ResNet-50`
- Embedding size: 2048

### Fusion + Classifier
- Concatenate text + image features
- Fully connected layers with dropout for classification

---

## âš™ï¸ Training Strategy

- Class-weighted Cross-Entropy to handle imbalance
- Partial fine-tuning (only last BERT layer)
- Optimizer: **AdamW**

---

## ğŸ“ˆ Results

### Performance on Validation Set

| Metric | Score |
|--------|-------|
| **Accuracy**     | 0.74 |
| **Macro F1-Score** | 0.74 |

### Confusion Matrix

[[186, 39, 19],
[ 65, 274, 45],
[ 36, 47, 263]]

## Model Hosting

The trained model (~538 MB) is hosted on the Hugging Face Model Hub to avoid GitHub file size limits.
The Streamlit app automatically downloads the model at runtime.

Model link:
https://huggingface.co/viaan7/multimodal-sentiment-bert-resnet


This shows balanced performance across all sentiment classes.

---

## ğŸŒ Streamlit App (Offline + Online)

### â–¶ï¸ Offline (Local Machine)

To run with full model inference:

1. Download the dataset
2. Place it under `MVSA_Single/`
3. Make sure `multimodal_model.pth` exists in project root
4. Run:

```bash
streamlit run streamlit_app.py
â˜ï¸ Online (Demo Mode)
For GitHub / Streamlit Cloud deployments, the model weights file is not included due to size.
In this case, the app:

âœ” Loads UI
âœ” Shows a clear warning that model weights are missing
âœ” Does not crash

To run full inference, users must place the weights locally.

ğŸ§  Notes for Users
You must download the dataset manually from Kaggle

Required project files assume dataset structure as shown above

Sending model weights over the web is optional, but locally supported

ğŸ“Œ One-Line Summary (Good for BIOS/Portfolio)
End-to-end multi-modal sentiment analysis using BERT + ResNet-50 with class-weighted training and Streamlit deployment.

ğŸ‘¨â€ğŸ’» Contact / Author
Viaan Sharma
M.Tech â€“ Mathematics & Computing (Machine Learning)
National Institute of Technology Delhi
